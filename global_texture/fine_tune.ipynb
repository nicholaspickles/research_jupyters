{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adjustment to gene.py to create the list\n",
    "\n",
    "import random, glob\n",
    "\n",
    "lines = []\n",
    "curr_path = \"/Users/nicholask/Desktop/Masters/research/Global_Texture_Enhancement_for_Fake_Face_Detection_in_the-Wild/stylegan-ffhq\"\n",
    "\n",
    "train_path = curr_path + \"/train_set\"\n",
    "train_real = train_path + \"/real\"\n",
    "train_fake = train_path + \"/fake\"\n",
    "\n",
    "test_path = curr_path + \"/test_set\"\n",
    "test_real = test_path + \"/real\"\n",
    "test_fake = test_path + \"/fake\"\n",
    "\n",
    "val_path = curr_path + \"/validate_set\"\n",
    "val_real = val_path + \"/real\"\n",
    "val_fake = val_path + \"/fake\"\n",
    "\n",
    "## 1 for real, 0 for fake\n",
    "\n",
    "# real_path = glob.glob(train_real+\"/*.png\")\n",
    "# for path in real_path:\n",
    "#     line = path + ' 1\\n'\n",
    "#     lines.append(line)\n",
    "\n",
    "# real_path = glob.glob(test_real + \"/*.png\")\n",
    "# for path in real_path:\n",
    "#     line = path + ' 1\\n'\n",
    "#     lines.append(line)\n",
    "\n",
    "# real_path = glob.glob(val_real + \"/*.png\")\n",
    "# for path in real_path:\n",
    "#     line = path + ' 1\\n'\n",
    "#     lines.append(line)\n",
    "\n",
    "# fake_path = glob.glob(train_fake + \"/*.png\")\n",
    "# for path in fake_path:\n",
    "#     line = path + ' 0\\n'\n",
    "#     lines.append(line)\n",
    "\n",
    "# fake_path = glob.glob(test_fake + \"/*.png\")\n",
    "# for path in fake_path:\n",
    "#     line = path + ' 0\\n'\n",
    "#     lines.append(line)\n",
    "\n",
    "# fake_path = glob.glob(val_fake + \"/*.png\")\n",
    "# for path in fake_path:\n",
    "#     line = path + ' 0\\n'\n",
    "#     lines.append(line)\n",
    "\n",
    "# f=open('list', 'w')\n",
    "# random.shuffle(lines)\n",
    "# for line in lines:\n",
    "#   f.write(line)\n",
    "# f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch,os,random\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms#, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import resnet18_gram as resnet\n",
    "import os,glob\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "from torch.autograd import Variable\n",
    "model_urls = {\n",
    "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
    "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
    "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
    "}\n",
    "\n",
    "normalize = transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406],\n",
    "    std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "preprocess = transforms.Compose([\n",
    "    #transforms.Scale(256),\n",
    "    #transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "root='./'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_loader(path):\n",
    "\n",
    "    size = random.randint(64, 256)\n",
    "\n",
    "    im=cv2.imread(path)\n",
    "    im=cv2.resize(im,(size,size))\n",
    "    im=cv2.resize(im,(512,512))\n",
    "    ims=np.zeros((3,512,512))\n",
    "    ims[0,:,:]=im[:,:,0]\n",
    "    ims[1,:,:]=im[:,:,1]\n",
    "    ims[2,:,:]=im[:,:,2]\n",
    "    img_tensor=torch.tensor(ims.astype('float32'))\n",
    "    \n",
    "    return img_tensor\n",
    "\n",
    "class customData(Dataset):\n",
    "    def __init__(self, img_path, txt_path, dataset = '', data_transforms=None, loader = default_loader):\n",
    "        with open(txt_path) as input_file:\n",
    "            lines = input_file.readlines()\n",
    "            self.img_name = [os.path.join(img_path, line.strip().split(' ')[0]) for line in lines]\n",
    "            self.img_label = [int(line.strip().split(' ')[-1]) for line in lines]\n",
    "        self.data_transforms = data_transforms\n",
    "        self.dataset = dataset\n",
    "        self.loader = loader\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_name)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        img_name = self.img_name[item]\n",
    "        label = self.img_label[item]\n",
    "        img = self.loader(img_name)\n",
    "\n",
    "        if self.data_transforms is not None:\n",
    "            try:\n",
    "                img = self.data_transforms[self.dataset](img)\n",
    "            except:\n",
    "                print(\"Cannot transform image: {}\".format(img_name))\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nicholask/opt/anaconda3/lib/python3.9/site-packages/torch/serialization.py:868: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/Users/nicholask/opt/anaconda3/lib/python3.9/site-packages/torch/serialization.py:868: SourceChangeWarning: source code of class 'torch.nn.modules.batchnorm.BatchNorm2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/Users/nicholask/opt/anaconda3/lib/python3.9/site-packages/torch/serialization.py:868: SourceChangeWarning: source code of class 'torch.nn.modules.activation.ReLU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/Users/nicholask/opt/anaconda3/lib/python3.9/site-packages/torch/serialization.py:868: SourceChangeWarning: source code of class 'torch.nn.modules.pooling.MaxPool2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/Users/nicholask/opt/anaconda3/lib/python3.9/site-packages/torch/serialization.py:868: SourceChangeWarning: source code of class 'torch.nn.modules.container.Sequential' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/Users/nicholask/opt/anaconda3/lib/python3.9/site-packages/torch/serialization.py:868: SourceChangeWarning: source code of class 'torch.nn.modules.pooling.AdaptiveAvgPool2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/Users/nicholask/opt/anaconda3/lib/python3.9/site-packages/torch/serialization.py:868: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/Users/nicholask/opt/anaconda3/lib/python3.9/site-packages/torch/serialization.py:868: SourceChangeWarning: source code of class 'torch.nn.modules.dropout.Dropout' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/Users/nicholask/opt/anaconda3/lib/python3.9/site-packages/torch/serialization.py:868: SourceChangeWarning: source code of class 'torch.nn.modules.activation.LogSoftmax' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (gram): GramMatrix()\n",
       "  (scale): ScaleLayer()\n",
       "  (fcnewr): Sequential(\n",
       "    (0): Linear(in_features=704, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=512, out_features=2, bias=True)\n",
       "    (4): LogSoftmax(dim=1)\n",
       "  )\n",
       "  (conv_interi_0): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_inter0_0): Sequential(\n",
       "    (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_inter1_0): Sequential(\n",
       "    (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_inter2_0): Sequential(\n",
       "    (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_inter3_0): Sequential(\n",
       "    (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv_inter4_0): Sequential(\n",
       "    (0): Conv2d(256, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (gi_fc1): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (gi_fc2): Sequential(\n",
       "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (g0_fc1): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (g0_fc2): Sequential(\n",
       "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (g_fc1r): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (g_fc2r): Sequential(\n",
       "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (g2_fc1): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (g2_fc2): Sequential(\n",
       "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (g3_fc1): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (g3_fc2): Sequential(\n",
       "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (g4_fc1): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (g4_fc2): Sequential(\n",
       "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_datasets = customData(img_path='',txt_path=('list')) #,\n",
    "                                    #data_transforms=data_transforms,\n",
    "                                    #dataset=x) for x in ['train', 'val']}\n",
    "\n",
    "dataloaders =  torch.utils.data.DataLoader(image_datasets,\n",
    "                                                 batch_size=14,\n",
    "                                                 shuffle=True) \n",
    "\n",
    "test_datasets = customData(img_path='',txt_path=('list')) #,\n",
    "                                    #data_transforms=data_transforms,\n",
    "                                    #dataset=x) for x in ['train', 'val']}\n",
    "\n",
    "testloader =  torch.utils.data.DataLoader(test_datasets,\n",
    "                                                 batch_size=1,\n",
    "                                                 shuffle=False) \n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = resnet.resnet18(pretrained=True) #resnet18_gram.resnet18() #pretrained=True)\n",
    "resnetinit=torch.load('stylegan-ffhq.pth', map_location = 'cpu')\n",
    "model.load_state_dict(resnetinit.state_dict(),strict=False)\n",
    "\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0003, weight_decay=1e-4)\n",
    "#model=torch.load('aerialmodel.pth')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tests\n",
    "\n",
    "## I will only test the ones that use stargan and ffhq since it is the 2 datasets that we got the images from\n",
    "\n",
    "## Unrealted test since it uses stargan\n",
    "def test0(model):\n",
    "  model.eval()\n",
    "  gt=0\n",
    "  corr=0\n",
    "  for i in range(0,100):\n",
    "     im=cv2.imread(root+'pngdata/stargan/'+str(i).zfill(6)+'.png')\n",
    "     ims = np.zeros((1, 3, 128, 128))\n",
    "     ims[0, 0, :, :] = im[:, :, 0]\n",
    "     ims[0, 1, :, :] = im[:, :, 1]\n",
    "     ims[0, 2, :, :] = im[:, :, 2]\n",
    "     image_tensor =torch.tensor(ims).float()\n",
    "     inputs = Variable(image_tensor).float().cuda()\n",
    "     output = model(inputs)\n",
    "     output=output.detach().cpu().numpy()\n",
    "     pred=np.argmax(output)\n",
    "     #print ('0',pred)\n",
    "     if pred==0:\n",
    "        corr+=1\n",
    "  return corr/100.0\n",
    "\n",
    "## Unrealted test since it uses stargan\n",
    "def test1(model):\n",
    "  model.eval()\n",
    "\n",
    "  gt=0\n",
    "  corr=0\n",
    "  for i in range(10000,10100):\n",
    "     im=cv2.imread(root+'pngdata/data/prog-gan-cele/'+str(i).zfill(6)+'.png')\n",
    "     '''rate=95\n",
    "     encode_param=[int(cv2.IMWRITE_JPEG_QUALITY),rate]\n",
    "     result,im=cv2.imencode('.jpg',im,encode_param)\n",
    "     im=cv2.imdecode(im,1)\n",
    "     if random.randint(0,1)==0:\n",
    "       im=cv2.resize(im,(64,64))\n",
    "     im=cv2.resize(im,(512,512))'''\n",
    "     ims = np.zeros((1, 3, 1024, 1024))\n",
    "     ims[0, 0, :, :] = im[:, :, 0]\n",
    "     ims[0, 1, :, :] = im[:, :, 1]\n",
    "     ims[0, 2, :, :] = im[:, :, 2]\n",
    "     image_tensor =torch.tensor(ims).float()\n",
    "     inputs = Variable(image_tensor).float().cuda()\n",
    "     output = model(inputs)\n",
    "     output=output.detach().cpu().numpy()\n",
    "     pred=np.argmax(output)\n",
    "     #print ('0',pred)\n",
    "     if pred==0:\n",
    "        corr+=1\n",
    "  return corr/50.0\n",
    "\n",
    "## Unrealted test since it uses stargan\n",
    "def test2(model):\n",
    "  model.eval()\n",
    "  gt=0\n",
    "  corr=0\n",
    "  for i in range(0,100):\n",
    "     im=cv2.imread(root+'pngdata/dcgan/'+str(i).zfill(6)+'.png')\n",
    "     ims = np.zeros((1, 3, 64, 64))\n",
    "     ims[0, 0, :, :] = im[:, :, 0]\n",
    "     ims[0, 1, :, :] = im[:, :, 1]\n",
    "     ims[0, 2, :, :] = im[:, :, 2]\n",
    "     image_tensor =torch.tensor(ims).float()\n",
    "     inputs = Variable(image_tensor).float().cuda()\n",
    "     output = model(inputs)\n",
    "     output=output.detach().cpu().numpy()\n",
    "     pred=np.argmax(output)\n",
    "     #print ('0',pred)\n",
    "     if pred==0:\n",
    "        corr+=1\n",
    "  return corr/100.0\n",
    "\n",
    "## Unrealted test since it uses stargan\n",
    "def test3(model):\n",
    "  model.eval()\n",
    "  gt=0\n",
    "  corr=0\n",
    "  paths=glob.glob(root+'pngdata/celeba-low-res/20????.png')\n",
    "  for path in paths:\n",
    "     im=cv2.imread(path)\n",
    "     ims = np.zeros((1, 3, 178, 178))\n",
    "     ims[0, 0, :, :] = im[:, :, 0]\n",
    "     ims[0, 1, :, :] = im[:, :, 1]\n",
    "     ims[0, 2, :, :] = im[:, :, 2]\n",
    "     image_tensor =torch.tensor(ims).float()\n",
    "     inputs = Variable(image_tensor).float().cuda()\n",
    "     output = model(inputs)\n",
    "     output=output.detach().cpu().numpy()\n",
    "     pred=np.argmax(output)\n",
    "     #print ('1',pred)\n",
    "     if pred==1:\n",
    "        corr+=1\n",
    "  return corr/131.0\n",
    "\n",
    "def test4(model):\n",
    "  model.eval()\n",
    "  gt=0\n",
    "  corr=0\n",
    "\n",
    "  real_path_test = glob.glob(test_real + \"/*.png\")\n",
    "  count = 0\n",
    "  for path in real_path_test:\n",
    "    if count == 50:\n",
    "      break\n",
    "  # original:\n",
    "  # for i in range(100,150):\n",
    "  #    im=cv2.imread(root+'pngdata/data/ffhq/'+str(i).zfill(6)+'.png')\n",
    "    im = cv2.imread(path)\n",
    "    rate=95\n",
    "    encode_param=[int(cv2.IMWRITE_JPEG_QUALITY),rate]\n",
    "    result,im=cv2.imencode('.jpg',im,encode_param)\n",
    "    im=cv2.imdecode(im,1)\n",
    "    if random.randint(0,1)==0:\n",
    "      im=cv2.resize(im,(64,64))\n",
    "    im=cv2.resize(im,(512,512))\n",
    "    ims = np.zeros((1, 3, 512,512))\n",
    "    ims[0, 0, :, :] = im[:, :, 0]\n",
    "    ims[0, 1, :, :] = im[:, :, 1]\n",
    "    ims[0, 2, :, :] = im[:, :, 2]\n",
    "    image_tensor =torch.tensor(ims).float()\n",
    "    ## Original is commented out because my Mac M1 trip does not have CUDA support\n",
    "    # inputs = Variable(image_tensor).float().cuda()\n",
    "    inputs = Variable(image_tensor).float()\n",
    "    output = model(inputs)\n",
    "    output=output.detach().cpu().numpy()\n",
    "    pred=np.argmax(output)\n",
    "    count += 1\n",
    "    #print ('0',pred)\n",
    "    if pred==1:\n",
    "      corr+=1\n",
    "  return corr/50.0\n",
    "\n",
    "def test5(model):\n",
    "  model.eval()\n",
    "  gt=0\n",
    "  corr=0\n",
    "\n",
    "  fake_path_test = glob.glob(test_fake + \"/*.png\")\n",
    "  count = 0\n",
    "  for path in fake_path_test:\n",
    "    if count == 50:\n",
    "      break\n",
    "  # for i in range(100,150):\n",
    "  #    im=cv2.imread(root+'pngdata/data/style-ffhq/'+str(i).zfill(6)+'.png')\n",
    "    im=cv2.imread(path)\n",
    "    rate=95\n",
    "    encode_param=[int(cv2.IMWRITE_JPEG_QUALITY),rate]\n",
    "    result,im=cv2.imencode('.jpg',im,encode_param)\n",
    "    im=cv2.imdecode(im,1)\n",
    "    if random.randint(0,1)==0:\n",
    "      im=cv2.resize(im,(64,64))\n",
    "    im=cv2.resize(im,(512,512))\n",
    "    ims = np.zeros((1, 3, 512,512))\n",
    "    ims[0, 0, :, :] = im[:, :, 0]\n",
    "    ims[0, 1, :, :] = im[:, :, 1]\n",
    "    ims[0, 2, :, :] = im[:, :, 2]\n",
    "    image_tensor =torch.tensor(ims).float()\n",
    "    ## Original is commented out because my Mac M1 trip does not have CUDA support\n",
    "  #  inputs = Variable(image_tensor).float().cuda()\n",
    "    inputs = Variable(image_tensor).float()\n",
    "    output = model(inputs)\n",
    "    output=output.detach().cpu().numpy()\n",
    "    pred=np.argmax(output)\n",
    "\n",
    "    count += 1\n",
    "    #print ('0',pred)\n",
    "    if pred==0:\n",
    "      corr+=1\n",
    "  return corr/50.0\n",
    "\n",
    "## Unrealted test since it uses stargan\n",
    "def test6(model):\n",
    "  model.eval()\n",
    "\n",
    "  gt=0\n",
    "  corr=0\n",
    "  for i in range(10000,10050):\n",
    "     im=cv2.imread(root+'pngdata/data/style-cele/'+str(i).zfill(6)+'.png')\n",
    "     ims = np.zeros((1, 3, 1024, 1024))\n",
    "     ims[0, 0, :, :] = im[:, :, 0]\n",
    "     ims[0, 1, :, :] = im[:, :, 1]\n",
    "     ims[0, 2, :, :] = im[:, :, 2]\n",
    "     image_tensor =torch.tensor(ims).float()\n",
    "     inputs = Variable(image_tensor).float().cuda()\n",
    "     output = model(inputs)\n",
    "     output=output.detach().cpu().numpy()\n",
    "     pred=np.argmax(output)\n",
    "     #print ('0',pred)\n",
    "     if pred==0:\n",
    "        corr+=1\n",
    "  return corr/50.0\n",
    "\n",
    "## Unrealted test since it uses stargan\n",
    "def test7(model):\n",
    "  model.eval()\n",
    "\n",
    "  gt=0\n",
    "  corr=0\n",
    "  for i in range(10000,10040):\n",
    "     im=cv2.imread(root+'pngdata/data/celeba-1024/'+str(i)+'.jpg')\n",
    "     ims = np.zeros((1, 3, 1024, 1024))\n",
    "     ims[0, 0, :, :] = im[:, :, 0]\n",
    "     ims[0, 1, :, :] = im[:, :, 1]\n",
    "     ims[0, 2, :, :] = im[:, :, 2]\n",
    "     image_tensor =torch.tensor(ims).float()\n",
    "     inputs = Variable(image_tensor).float().cuda()\n",
    "     output = model(inputs)\n",
    "     output=output.detach().cpu().numpy()\n",
    "     pred=np.argmax(output)\n",
    "     #print ('0',pred)\n",
    "     if pred==1:\n",
    "        corr+=1\n",
    "  return corr/40.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0\n",
      "1.94 0\n",
      "1.88 1.94\n",
      "1.92 1.94\n",
      "1.98 1.94\n",
      "1.88 1.98\n",
      "1.92 1.98\n",
      "1.9 1.98\n",
      "1.88 1.98\n",
      "1.92 1.98\n",
      "1.8199999999999998 1.98\n",
      "1.7999999999999998 1.98\n",
      "1.88 1.98\n",
      "1.8199999999999998 1.98\n",
      "1.76 1.98\n",
      "1.78 1.98\n",
      "1.8 1.98\n",
      "1.8599999999999999 1.98\n",
      "1.9 1.98\n",
      "1.8399999999999999 1.98\n",
      "1.88 1.98\n",
      "1.8599999999999999 1.98\n",
      "1.8599999999999999 1.98\n",
      "1.88 1.98\n",
      "1.8399999999999999 1.98\n",
      "1.8199999999999998 1.98\n",
      "1.8599999999999999 1.98\n",
      "1.8599999999999999 1.98\n",
      "1.88 1.98\n",
      "1.88 1.98\n",
      "1.8399999999999999 1.98\n",
      "1.9 1.98\n",
      "1.92 1.98\n",
      "1.9 1.98\n",
      "1.92 1.98\n",
      "1.9 1.98\n",
      "1.8599999999999999 1.98\n",
      "1.92 1.98\n",
      "1.88 1.98\n",
      "1.92 1.98\n",
      "1.8599999999999999 1.98\n",
      "1.88 1.98\n",
      "1.8599999999999999 1.98\n",
      "1.88 1.98\n",
      "1.92 1.98\n",
      "1.94 1.98\n",
      "1.94 1.98\n",
      "1.94 1.98\n",
      "1.92 1.98\n",
      "1.96 1.98\n",
      "1.92 1.98\n",
      "1.94 1.98\n",
      "1.94 1.98\n",
      "1.9 1.98\n",
      "1.94 1.98\n",
      "1.94 1.98\n",
      "1.98 1.98\n",
      "1.94 1.98\n",
      "1.96 1.98\n",
      "1.96 1.98\n",
      "1.94 1.98\n",
      "1.94 1.98\n",
      "1.94 1.98\n",
      "1.92 1.98\n",
      "1.9 1.98\n",
      "1.94 1.98\n",
      "1.96 1.98\n",
      "1.94 1.98\n",
      "1.98 1.98\n",
      "1.96 1.98\n",
      "1.96 1.98\n",
      "1.96 1.98\n",
      "1.96 1.98\n",
      "2.0 1.98\n",
      "1.98 2.0\n",
      "1.96 2.0\n",
      "1.94 2.0\n",
      "1.96 2.0\n",
      "1.94 2.0\n",
      "1.96 2.0\n",
      "1.98 2.0\n",
      "1.96 2.0\n",
      "1.94 2.0\n",
      "1.96 2.0\n",
      "1.94 2.0\n",
      "1.98 2.0\n",
      "1.96 2.0\n",
      "1.94 2.0\n",
      "1.94 2.0\n",
      "1.96 2.0\n",
      "1.94 2.0\n",
      "1.94 2.0\n",
      "1.94 2.0\n",
      "1.98 2.0\n",
      "1.98 2.0\n",
      "1.98 2.0\n",
      "1.98 2.0\n",
      "1.98 2.0\n",
      "1.98 2.0\n",
      "1.96 2.0\n",
      "1.98 2.0\n",
      "1.96 2.0\n",
      "1.96 2.0\n",
      "1.96 2.0\n",
      "1.94 2.0\n",
      "1.96 2.0\n",
      "1.96 2.0\n",
      "1.96 2.0\n",
      "1.96 2.0\n",
      "1.94 2.0\n",
      "1.98 2.0\n",
      "1.94 2.0\n",
      "1.94 2.0\n",
      "1.96 2.0\n",
      "1.98 2.0\n",
      "1.92 2.0\n",
      "1.94 2.0\n",
      "1.98 2.0\n",
      "1.96 2.0\n",
      "1.94 2.0\n",
      "1.92 2.0\n",
      "1.9 2.0\n",
      "1.9 2.0\n",
      "1.9 2.0\n",
      "1.88 2.0\n",
      "1.92 2.0\n",
      "1.94 2.0\n",
      "1.94 2.0\n",
      "1.88 2.0\n",
      "1.92 2.0\n",
      "1.94 2.0\n",
      "1.96 2.0\n",
      "1.98 2.0\n",
      "1.98 2.0\n",
      "1.96 2.0\n",
      "1.96 2.0\n",
      "1.98 2.0\n",
      "1.96 2.0\n",
      "1.98 2.0\n",
      "1.96 2.0\n",
      "1.96 2.0\n",
      "1.98 2.0\n",
      "1.96 2.0\n",
      "1.98 2.0\n",
      "Epoch  1\n",
      "1.96 2.0\n",
      "1.96 2.0\n",
      "1.98 2.0\n",
      "1.96 2.0\n",
      "1.98 2.0\n",
      "1.96 2.0\n",
      "1.96 2.0\n",
      "1.98 2.0\n",
      "1.98 2.0\n",
      "1.98 2.0\n",
      "1.98 2.0\n",
      "1.98 2.0\n",
      "1.98 2.0\n",
      "1.98 2.0\n",
      "1.96 2.0\n",
      "1.94 2.0\n",
      "1.98 2.0\n",
      "1.96 2.0\n",
      "1.94 2.0\n",
      "1.98 2.0\n",
      "1.96 2.0\n",
      "1.98 2.0\n",
      "1.98 2.0\n",
      "1.98 2.0\n",
      "1.96 2.0\n",
      "1.94 2.0\n",
      "1.96 2.0\n",
      "1.98 2.0\n",
      "1.98 2.0\n",
      "1.98 2.0\n",
      "1.96 2.0\n",
      "1.98 2.0\n",
      "1.96 2.0\n",
      "1.96 2.0\n",
      "1.96 2.0\n",
      "1.94 2.0\n",
      "1.96 2.0\n",
      "1.94 2.0\n",
      "1.96 2.0\n",
      "1.98 2.0\n",
      "1.96 2.0\n",
      "1.94 2.0\n",
      "1.94 2.0\n",
      "1.92 2.0\n",
      "1.96 2.0\n",
      "1.96 2.0\n",
      "1.98 2.0\n",
      "1.94 2.0\n",
      "1.94 2.0\n",
      "1.98 2.0\n",
      "1.9 2.0\n",
      "1.9 2.0\n",
      "1.92 2.0\n",
      "1.94 2.0\n",
      "1.94 2.0\n",
      "1.88 2.0\n",
      "1.92 2.0\n",
      "1.94 2.0\n",
      "1.8599999999999999 2.0\n",
      "1.88 2.0\n",
      "1.88 2.0\n",
      "1.92 2.0\n",
      "1.94 2.0\n",
      "1.94 2.0\n",
      "1.92 2.0\n",
      "1.94 2.0\n",
      "1.8599999999999999 2.0\n",
      "1.96 2.0\n",
      "1.94 2.0\n",
      "1.92 2.0\n",
      "1.92 2.0\n",
      "1.8199999999999998 2.0\n",
      "1.9 2.0\n",
      "1.8399999999999999 2.0\n",
      "1.94 2.0\n",
      "1.92 2.0\n",
      "1.92 2.0\n",
      "1.94 2.0\n",
      "1.94 2.0\n",
      "1.9 2.0\n",
      "1.96 2.0\n",
      "1.9 2.0\n",
      "1.98 2.0\n",
      "1.94 2.0\n",
      "1.92 2.0\n",
      "1.92 2.0\n",
      "1.94 2.0\n",
      "1.92 2.0\n",
      "1.88 2.0\n",
      "1.9 2.0\n",
      "1.88 2.0\n",
      "1.94 2.0\n",
      "1.9 2.0\n",
      "1.94 2.0\n",
      "1.92 2.0\n",
      "1.9 2.0\n",
      "1.9 2.0\n",
      "1.8599999999999999 2.0\n",
      "1.9 2.0\n",
      "1.88 2.0\n",
      "1.94 2.0\n",
      "1.92 2.0\n",
      "1.92 2.0\n",
      "1.88 2.0\n",
      "1.8599999999999999 2.0\n",
      "1.8199999999999998 2.0\n",
      "1.74 2.0\n",
      "1.76 2.0\n",
      "1.72 2.0\n",
      "1.76 2.0\n",
      "1.6800000000000002 2.0\n",
      "1.74 2.0\n",
      "1.8199999999999998 2.0\n",
      "1.78 2.0\n",
      "1.8199999999999998 2.0\n",
      "1.8599999999999999 2.0\n",
      "1.88 2.0\n",
      "1.92 2.0\n",
      "1.8599999999999999 2.0\n",
      "1.8399999999999999 2.0\n",
      "1.88 2.0\n",
      "1.96 2.0\n",
      "1.9 2.0\n",
      "1.92 2.0\n",
      "1.8599999999999999 2.0\n",
      "1.88 2.0\n",
      "1.9 2.0\n",
      "1.9 2.0\n",
      "1.9 2.0\n",
      "1.92 2.0\n",
      "1.92 2.0\n",
      "1.9 2.0\n",
      "1.92 2.0\n",
      "1.9 2.0\n",
      "1.9 2.0\n",
      "1.94 2.0\n",
      "1.94 2.0\n",
      "1.92 2.0\n",
      "1.96 2.0\n",
      "1.92 2.0\n",
      "1.94 2.0\n",
      "1.94 2.0\n",
      "1.92 2.0\n",
      "Epoch  2\n",
      "1.98 2.0\n",
      "1.96 2.0\n",
      "1.96 2.0\n",
      "1.94 2.0\n",
      "1.96 2.0\n",
      "1.9 2.0\n",
      "1.96 2.0\n",
      "1.92 2.0\n",
      "1.94 2.0\n",
      "1.94 2.0\n",
      "1.96 2.0\n",
      "1.92 2.0\n",
      "1.96 2.0\n",
      "1.96 2.0\n",
      "1.98 2.0\n",
      "1.94 2.0\n",
      "1.94 2.0\n",
      "1.88 2.0\n",
      "1.96 2.0\n",
      "1.8599999999999999 2.0\n",
      "1.92 2.0\n",
      "1.92 2.0\n",
      "1.88 2.0\n",
      "1.92 2.0\n",
      "1.88 2.0\n",
      "1.9 2.0\n",
      "1.94 2.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/xb/vcm7m5fx6w78mbc2pfhg09c80000gn/T/ipykernel_44553/24143884.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m       \u001b[0;31m# r1=test1(model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m       \u001b[0mr4\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m       \u001b[0mr5\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m       \u001b[0;31m# r6=test6(model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m       \u001b[0;31m# r7=test7(model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/xb/vcm7m5fx6w78mbc2pfhg09c80000gn/T/ipykernel_44553/944258873.py\u001b[0m in \u001b[0;36mtest5\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m    162\u001b[0m   \u001b[0;31m#  inputs = Variable(image_tensor).float().cuda()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m     \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0mpred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Masters/research/Global_Texture_Enhancement_for_Fake_Face_Detection_in_the-Wild/stylegan-ffhq/resnet18_gram.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0mg2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0mg2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m         \u001b[0mg3\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_inter3_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0mg3\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    457\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 459\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    460\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr=0.00001\n",
    "for param_group in optimizer.param_groups:\n",
    "  param_group['lr']=lr\n",
    "\n",
    "\n",
    "def get_lr(optimizer):\n",
    "  lr=[]\n",
    "  for param_group in optimizer.param_groups:\n",
    "    lr+=[param_group['lr']]\n",
    "  return lr\n",
    "epochs = 5\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "print_every = 1000\n",
    "train_losses, test_losses = [], []\n",
    "\n",
    "\n",
    "maxi=0\n",
    "for epoch in range(epochs):\n",
    "  print(\"Epoch \", epoch)\n",
    "  for inputs,labels in dataloaders:\n",
    "      model.train()\n",
    "      steps += 1\n",
    "      inputs, labels = inputs.to(device), labels.to(device)\n",
    "      optimizer.zero_grad()\n",
    "      logps = model.forward(inputs)\n",
    "      loss = criterion(logps, labels)\n",
    "      # print (loss,'loss',epoch)\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      running_loss += loss.item()\n",
    "\n",
    "      ## commented out tests are not ffhq or style-gan\n",
    "      # r1=test1(model)\n",
    "      r4=test4(model)\n",
    "      r5=test5(model)\n",
    "      # r6=test6(model)\n",
    "      # r7=test7(model)\n",
    "      \n",
    "      score= r4 + r5\n",
    "      print (r4 + r5,maxi)\n",
    "      if score>maxi:\n",
    "          maxi=score\n",
    "  \n",
    "          torch.save(model, 'aerialmodel'+str(len(glob.glob('*.pth')))+'.pth')\n",
    "\n",
    "      #if steps%100==0:\n",
    "      #  torch.save(model, 'aerialmodel'+str(len(glob.glob('*.pth')))+'.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 10.4826, Test Accuracy: 0.5025\n"
     ]
    }
   ],
   "source": [
    "model_ft = torch.load(\"aerialmodel8.pth\", map_location='cpu')\n",
    "test_path = \"/Users/nicholask/Desktop/Masters/research/Global_Texture_Enhancement_for_Fake_Face_Detection_in_the-Wild/stylegan-ffhq/test_set\"\n",
    "\n",
    "transformer = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(size=(256, 256), scale=(0.25, 1.0), ratio=(0.8, 1.2)),\n",
    "    transforms.Resize(size=(64, 64), interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5,0.5,0.5], [0.5,0.5,0.5])\n",
    "])\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    datasets.ImageFolder(test_path, transform=transformer),\n",
    "    batch_size = 4,\n",
    "    shuffle=True,\n",
    "    num_workers = 4\n",
    ")\n",
    "# keep track of the loss and accuracy\n",
    "test_loss = 0.0\n",
    "test_accuracy = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model_ft(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        test_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct = (predicted == labels).sum().item()\n",
    "        test_accuracy += correct\n",
    "\n",
    "# calculate average loss and accuracy\n",
    "test_loss = test_loss / len(test_loader.dataset)\n",
    "test_accuracy = test_accuracy / len(test_loader.dataset)\n",
    "\n",
    "print('Test Loss: {:.4f}, Test Accuracy: {:.4f}'.format(test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
